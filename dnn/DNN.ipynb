{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from tests import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An L-layered binary classifier neural network.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Back-propagation for the model. Has internal ReLUs and a sigmoid for the L-th layer.\n",
    "    \n",
    "    Arguments:\n",
    "    :param AL: \n",
    "                - Probability vector resultant of forward propagation.\n",
    "    :param Y: \n",
    "                - Truth vector provided by the user.\n",
    "    :param caches: List of caches of shape (linear_cache, activation_cache) of length L\n",
    "                - The caches contain the saved data from the forward propagation segment.\n",
    "    \n",
    "    Returns:\n",
    "    :return gradients: \n",
    "    \"\"\"\n",
    "    gradients = {}           # initialization of the gradients dictionary\n",
    "    L = len(caches)          # number of layers\n",
    "    print(str(L))\n",
    "    m = AL.shape[1]          # number of data samples (total training samples)\n",
    "    Y = Y.reshape(AL.shape)  # reshape Y to be the same as AL for matrix multiplication\n",
    "    # Calculate L-th layer derivative to initiate the back-propagation:\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    # Access the L-th layer caches:\n",
    "    current_cache = caches[L - 1]\n",
    "    # Add the L-th layer sigmoid gradients to our dictionary:\n",
    "    dA_prev_temp, dW_temp, db_temp = backward_activation(dAL, current_cache, \"sigmoid\")\n",
    "    gradients[\"dA\" + str(L - 1)] = dA_prev_temp\n",
    "    gradients[\"dW\" + str(L)] = dW_temp\n",
    "    gradients[\"db\" + str(L)] = db_temp\n",
    "    \n",
    "    # Calculate each gradient for the internal ReLU layers:\n",
    "    for l in reversed(range(L - 1)):\n",
    "        # Update the cache:\n",
    "        current_cache = caches[l]\n",
    "        # Add dA, dW and db to our gradients dictionary:\n",
    "        dA_prev_temp, dW_temp, db_temp = \\\n",
    "            backward_activation(gradients[\"dA\" + str(l + 1)], current_cache, \"ReLU\")\n",
    "        gradients[\"dA\" + str(l)] = dA_prev_temp\n",
    "        gradients[\"dW\" + str(l + 1)] = dW_temp\n",
    "        gradients[\"db\" + str(l + 1)] = db_temp\n",
    "    return gradients\n",
    "\n",
    "\n",
    "def backward_linear(dZ, full_cache):\n",
    "    \"\"\"\n",
    "    The linear segment of back-propagation for an arbitrary layer l.\n",
    "    \n",
    "    Arguments:\n",
    "    :param dZ: \n",
    "                - Gradient of the cost with respect to the linear output for the layer l.\n",
    "    :param linear_cache: tuple of shape (A_prev, W, b)\n",
    "                - The saved values from forward propagation.\n",
    "    :param m: \n",
    "                - Count of all training samples.\n",
    "\n",
    "    Returns:\n",
    "    :return dW: same shape as W\n",
    "                - Gradient of the cost with respect to W (weights).\n",
    "    :return db: same shape as b\n",
    "                - Gradient of the cost with respect to b (biases).\n",
    "    :return dA: same shape as A_prev\n",
    "                - Gradient of the cost with respect to the activation (of the previous layer, l - 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open the cache:\n",
    "    linear_cache, activation_cache = full_cache\n",
    "    # Fetch W, b, and A_prev from the cache saved from our forward step:\n",
    "    A_prev, W, b = linear_cache\n",
    "    # Calculate the count of our training samples:\n",
    "    m = A_prev.shape[1]\n",
    "    # Derive weights:\n",
    "    dW = (1 / m) * np.dot(dZ, linear_cache[0].T)\n",
    "    # Derive biases:\n",
    "    db = (1 / m) * np.sum(dZ)\n",
    "    # Derive the activations:\n",
    "    dA_prev = np.dot(linear_cache[1].T, dZ)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "def backward_activation(dA, full_cache, activation=\"ReLU\"):\n",
    "    \"\"\"\n",
    "    Back-propagation segment for post-linear activation.\n",
    "    \n",
    "    Arguments:\n",
    "    :param dA: \n",
    "                - Post-activation gradient for current layer l.\n",
    "    :param full_cache:\n",
    "                - Both linear_- and activation_-caches.\n",
    "    :param activation: string\n",
    "                - The type of activation function to used, either \"ReLU\" or \"sigmoid\".\n",
    "    \n",
    "    Returns:\n",
    "    :return dW: same shape as W\n",
    "                - Gradient of the cost with respect to W (weights).\n",
    "    :return db: same shape as b\n",
    "                - Gradient of the cost with respect to b (biases).\n",
    "    :return dA_prev: same shape as A_prev\n",
    "                - Gradient of the cost with respect to the activation (of the previous layer, l - 1).\n",
    "    \"\"\"\n",
    "    # Unpack the cache:\n",
    "    linear_cache, activation_cache = full_cache\n",
    "    \n",
    "    # Split into the appropriate activation function:\n",
    "    if activation == \"ReLU\":\n",
    "        # Derive sigmoid:\n",
    "        dZ = sigmoid_backwards(dA, activation_cache)\n",
    "        # Back-propagate on the linear values post-dZ:\n",
    "        dA_prev, dW, db = backward_linear(dZ, full_cache)\n",
    "    elif activation == \"sigmoid\":\n",
    "        # Derive sigmoid:\n",
    "        dZ = relu_backwards(dA, activation_cache)\n",
    "        # Back-propagate on the linear values post-dZ:\n",
    "        dA_prev, dW, db = backward_linear(dZ, full_cache)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "def calc_cost(AL, Y):\n",
    "    # Count the number of training samples:\n",
    "    m = Y.shape[1]\n",
    "    # Evaluate the logarithmic cost function:\n",
    "    cost = - (1 / m) * np.sum(np.dot(Y, np.log(AL.T) + np.dot((1 - Y), np.log(1 - AL.T))))\n",
    "    # Reformat the cost:\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost\n",
    "\n",
    "\n",
    "def forward(X, parameters):\n",
    "    # Z = forward_activity(A, W, b)\n",
    "    # A = forward_activation(Z, activation)\n",
    "    # We need to return an array of caches so we can use the saved values for backprop\n",
    "    # We return the the final activity, AL, A[L], of our forward propagation step so that\n",
    "    #   it can be used as the input for back-propagation\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    caches = []\n",
    "    \n",
    "    # Loop over every layer:\n",
    "    for l in range(1, L):\n",
    "        # Reset our A_prev to reference the A from the previous iteration:\n",
    "        A_prev = A\n",
    "        \n",
    "        A, cache = forward_activation(A_prev, parameters[\"W\" + str(l)], parameters[\"b\" + str(l)], \"ReLU\")\n",
    "        \n",
    "        # Append the full cache to the list of caches:\n",
    "        caches.append(cache)\n",
    "    # Save the weights of the last layer into the parameters dictionary:\n",
    "    AL, cache = forward_activation(A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    assert(AL.shape == (1, X.shape[1]))\n",
    "    return AL, caches\n",
    "\n",
    "\n",
    "def forward_activation(A_prev, W, b, activation=\"ReLU\"):\n",
    "    \"\"\"\n",
    "    Helper which handles calling the appropriate activation function.\n",
    "    \n",
    "    :param Z: \n",
    "    :param W: \n",
    "    :param b: \n",
    "    :param activation: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"ReLU\":\n",
    "        Z, linear_cache = forward_linear(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    elif activation == \"sigmoid\":\n",
    "        Z, linear_cache = forward_linear(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        \n",
    "    assert(A.shape == (W.shape[0], Z.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def forward_linear(A, W, b):\n",
    "    \"\"\"\n",
    "    The linear segment of a layer's forward propagation.\n",
    "    \n",
    "    Arguments:\n",
    "    :param A: (size of previous layer, number of data samples)\n",
    "                -activations from the previous layer (or X, input data, for the 0-th layer)\n",
    "    :param W: numpy array of shape (size of current layer, size of previous layer)\n",
    "                -weights matrix\n",
    "    :param b: numpy array of shape (size of current layer, 1)\n",
    "                -bias vector\n",
    "    \n",
    "    Returns:\n",
    "    :return Z:\n",
    "                -the input of the activation function (also known as the pre-activation parameter)\n",
    "    :return cache: python dictionary containing \"A\", \"W\", and \"b\"\n",
    "                -stores forward-pass data for use later during backwards propagation\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = np.dot(W, A) + b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    assert Z.shape == (W.shape[0], A.shape[1]), \"Not getting a proper dimension for Z (activity)\"\n",
    "    return Z, cache\n",
    "\n",
    "\n",
    "def initialize_parameters(layers):\n",
    "    \"\"\"\n",
    "    Initializes the weights and biases for every layer of an l-layered neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    :param layers: a Python array where the index is the layer and the value is the number of units in layer index\n",
    "    \n",
    "    Returns:\n",
    "    :return parameters: Python dictionary containing \"W1\", \"b1\", ..., \"WL\", \"bL\"\n",
    "                         - Wl: weights for l with shape: (layers[l], layers[l - 1])\n",
    "                         - bl: biases  for l with shape: (layers[l], 1)\n",
    "    \"\"\"\n",
    "    L = len(layers)\n",
    "    parameters = {}\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters[\"W\" + str(l)] = np.random.randn(layers[l], layers[l - 1]) * 0.01\n",
    "        parameters[\"b\" + str(l)] = np.zeros((layers[l], 1))\n",
    "        assert(parameters[\"W\" + str(l)].shape == (layers[l], layers[l - 1]))\n",
    "        assert(parameters[\"b\" + str(l)].shape == (layers[l], 1))\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def train(X, Y, layers, learning_rate, num_iterations=2500):\n",
    "    parameters = initialize_parameters(layers)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        # Run the model:\n",
    "        AL, caches = forward(X, parameters)\n",
    "        # print(str(AL))\n",
    "        \n",
    "        # Calculate the cost:\n",
    "        cost = calc_cost(AL, Y)\n",
    "        \n",
    "        # Back-propagate the model:\n",
    "        gradients = backward(AL, Y, caches)\n",
    "        \n",
    "        # Run gradient descent and update parameters:\n",
    "        parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "        \n",
    "        # Print the cost at every iteration:\n",
    "        print(\"Cost at iteration \" + str(i) + \": \" + str(cost))\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def update_parameters(parameters, gradients, learning_rate=0.001):\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * \\\n",
    "            gradients[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * \\\n",
    "            gradients[\"db\" + str(l + 1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0. It's a non-cat picture.\ntrain_x's shape: (12288, 209)\ntest_x's shape: (12288, 50)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import load_data\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# %autoreload 2\n",
    "\n",
    "np.random.seed(1)\n",
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n",
    "\n",
    "index = 49\n",
    "plt.imshow(train_x_orig[index])\n",
    "print (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")\n",
    "\n",
    "# Reshape the training and test examples \n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "print (\"train_x's shape: \" + str(train_x.shape))\n",
    "print (\"test_x's shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\nCost at iteration 0: 32.95293704395234\n4\nCost at iteration 1: 32.843764891086735\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the dimensions of the model with respect to the dataset\n",
    "# layers_dims = [12288, 20, 7, 5, 1]  # 4-layer model\n",
    "# parameters = train(train_x, train_y, layers_dims, 0.0075, num_iterations = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "stem_cell": {
   "cell_type": "raw",
   "source": "",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
